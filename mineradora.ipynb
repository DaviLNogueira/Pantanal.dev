{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bs4) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4->bs4) (2.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bs4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.28.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (2022.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Essas credenciais s√£o de um usuario meu da Amazon AWS\n",
    "##### Retirar ao enviar para o github, e colocar as suas credenciais ao minerar\n",
    "\n",
    "##### Pegar User agent especifico para o seu PC: https://www.whatismybrowser.com/detect/what-is-my-user-agent/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My acess key from Aws\n",
    "ACESS_KEY = \"AKIAZMB4B3QQGC5JGR7R\"\n",
    "SECRET_KEY = \"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\"\n",
    "USER_AGENT = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36 OPR/97.0.0.0\"\n",
    "\n",
    "HEADERS = ({'User-Agent': USER_AGENT, 'Accept-Language': 'pt-br;q=0.5', 'x-amz-access-key': ACESS_KEY, 'x-amz-secret-key': SECRET_KEY})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract Product Title\n",
    "def get_title(soup):\n",
    "\n",
    "    try:\n",
    "        # Outer Tag Object\n",
    "        title = soup.find(\"a\", attrs={\"data-hook\":'product-link'})\n",
    "        \n",
    "        # Inner NavigatableString Object\n",
    "        title_value = title.text\n",
    "\n",
    "        # Title as a string value\n",
    "        title_string = title_value.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        title_string = \"\"\n",
    "\n",
    "    return title_string\n",
    "\n",
    "def get_review_comments(soup):\n",
    "    array_of_comments = []\n",
    "    try:\n",
    "        review_comment = soup.find_all(\"span\", attrs={\"class\": \"cr-original-review-content\"})\n",
    "\n",
    "        for review in review_comment:\n",
    "            array_of_comments.append(review.string.strip())\n",
    "    \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "    return array_of_comments\n",
    "\n",
    "def get_reviews(soup, dictionary):\n",
    "    reviews = get_review_comments(soup)\n",
    "\n",
    "    for review in reviews:\n",
    "        dictionary['produto'].append(get_title(soup))\n",
    "        dictionary['avaliacoes'].append(review)\n",
    "\n",
    "#* This function can be used later for paging, when searching for products, and only that by the moment\n",
    "def get_next_page_of_search(soup): \n",
    "    page = soup.find('ul', attrs={'class': 'a-pagination'})\n",
    "    if not page.find('li', attrs={'class': 'a-disabled a-last'}):\n",
    "        url = str(page.find('li', attrs={'class': 'a-last'}).find('a')['href'])\n",
    "        return url\n",
    "    \n",
    "    else:\n",
    "        return\n",
    "\n",
    "def get_next_page_of_reviews(soup):\n",
    "    next_page = soup.find(\"ul\", attrs={'class': 'a-pagination'})\n",
    "\n",
    "    if next_page is not None:\n",
    "        next_page = next_page.find(\"li\", attrs={'class': 'a-last'})\n",
    "\n",
    "    else:\n",
    "        next_page = None\n",
    "\n",
    "    return next_page\n",
    "\n",
    "def mine_links(links_list, base_dictionary):\n",
    "    \n",
    "    d = {}\n",
    "\n",
    "    for key in base_dictionary:\n",
    "        d.setdefault(key, [])\n",
    "\n",
    "\n",
    "    for link in links_list:\n",
    "\n",
    "        new_webpage = requests.get(\"https://www.amazon.com\" + link, headers=HEADERS)\n",
    "\n",
    "        new_soup = BeautifulSoup(new_webpage.content, \"html.parser\")\n",
    "\n",
    "        link_to_review = new_soup.find(\"a\", attrs={'data-hook': 'see-all-reviews-link-foot'})\n",
    "\n",
    "        if link_to_review is not None:\n",
    "            link_to_review = link_to_review.get('href')\n",
    "\n",
    "            new_webpage = requests.get(\"https://www.amazon.com\" + link_to_review + \"&sortBy=recent\", headers=HEADERS)\n",
    "            \n",
    "            new_soup = BeautifulSoup(new_webpage.content, \"html.parser\")\n",
    "\n",
    "            get_reviews(new_soup, d)\n",
    "\n",
    "            next_page = get_next_page_of_reviews(new_soup) \n",
    "            \n",
    "            counter_page = 2\n",
    "\n",
    "            while (next_page is not None) and counter_page < 100:\n",
    "                index_ref = link_to_review.find('ref') - 1\n",
    "                index_product_reviews = link_to_review.find('s') + 2\n",
    "\n",
    "                product_id = link_to_review[index_product_reviews: index_ref]\n",
    "\n",
    "                url = f\"https://www.amazon.com/reviews/{product_id}?pageNumber={counter_page}&pageSize=10&sortBy=recent\"\n",
    "\n",
    "                new_webpage = requests.get(url, params=counter_page,headers=HEADERS)\n",
    "\n",
    "                new_soup = BeautifulSoup(new_webpage.content, \"html.parser\")\n",
    "\n",
    "                get_reviews(new_soup, d)\n",
    "\n",
    "                next_page = get_next_page_of_reviews(new_soup)\n",
    "                \n",
    "                if counter_page%10 == 0:\n",
    "                    print(counter_page)\n",
    "\n",
    "                counter_page += 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "10\n",
      "20\n",
      "10\n",
      "20\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "10\n",
      "10\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # The webpage URL\n",
    "    URL = \"https://www.amazon.com/s?k=playstation&ref=nb_sb_noss_2\"\n",
    "\n",
    "    # HTTP Request\n",
    "    webpage = requests.get(URL, headers=HEADERS)\n",
    "\n",
    "    # Soup Object containing all data\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "\n",
    "    # Fetch links as List of Tag Objects\n",
    "    links = soup.find_all(\"a\", attrs={'class':'a-link-normal s-no-outline'})\n",
    "\n",
    "    # Store the links\n",
    "    links_list = []\n",
    "    review_link_list = []\n",
    "\n",
    "    # Loop for extracting links from Tag Objects\n",
    "    for link in links:\n",
    "        links_list.append(link.get('href'))\n",
    "\n",
    "\n",
    "    base_dictionary = {\"produto\":[], \"avaliacoes\":[]}\n",
    "    \n",
    "    # Loop for extracting product details from each link \n",
    "    # TODO Put this for in multithread processing\n",
    "    # TODO Add the reviews text and other things\n",
    "\n",
    "    d = mine_links(links_list, base_dictionary)\n",
    "    \n",
    "    amazon_df = pd.DataFrame.from_dict(d)\n",
    "    amazon_df['produto'].replace('', np.nan, inplace=True)\n",
    "    amazon_df = amazon_df.dropna(subset=['produto'])\n",
    "    amazon_df.to_csv(\"amazon_data.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>produto</th>\n",
       "      <th>avaliacoes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$50 PlayStation Store Gift Card [Digital Code]</td>\n",
       "      <td>What</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$50 PlayStation Store Gift Card [Digital Code]</td>\n",
       "      <td>Just bought it an tried to us the code an it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$50 PlayStation Store Gift Card [Digital Code]</td>\n",
       "      <td>Easy to use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$50 PlayStation Store Gift Card [Digital Code]</td>\n",
       "      <td>Easy to use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$50 PlayStation Store Gift Card [Digital Code]</td>\n",
       "      <td>Very handy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15152</th>\n",
       "      <td>OCG Fones de ouvido para jogos 2,4 GHz Bluetoo...</td>\n",
       "      <td>Awesome gaming headphones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15153</th>\n",
       "      <td>OCG Fones de ouvido para jogos 2,4 GHz Bluetoo...</td>\n",
       "      <td>These headphones are very comfortable and I li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15154</th>\n",
       "      <td>OCG Fones de ouvido para jogos 2,4 GHz Bluetoo...</td>\n",
       "      <td>Amazing Sound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15155</th>\n",
       "      <td>OCG Fones de ouvido para jogos 2,4 GHz Bluetoo...</td>\n",
       "      <td>Got these for my gamer 14yr old son. He says t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15156</th>\n",
       "      <td>OCG Fones de ouvido para jogos 2,4 GHz Bluetoo...</td>\n",
       "      <td>Excellent but can be improved more</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15157 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 produto  \\\n",
       "0         $50 PlayStation Store Gift Card [Digital Code]   \n",
       "1         $50 PlayStation Store Gift Card [Digital Code]   \n",
       "2         $50 PlayStation Store Gift Card [Digital Code]   \n",
       "3         $50 PlayStation Store Gift Card [Digital Code]   \n",
       "4         $50 PlayStation Store Gift Card [Digital Code]   \n",
       "...                                                  ...   \n",
       "15152  OCG Fones de ouvido para jogos 2,4 GHz Bluetoo...   \n",
       "15153  OCG Fones de ouvido para jogos 2,4 GHz Bluetoo...   \n",
       "15154  OCG Fones de ouvido para jogos 2,4 GHz Bluetoo...   \n",
       "15155  OCG Fones de ouvido para jogos 2,4 GHz Bluetoo...   \n",
       "15156  OCG Fones de ouvido para jogos 2,4 GHz Bluetoo...   \n",
       "\n",
       "                                              avaliacoes  \n",
       "0                                                   What  \n",
       "1      Just bought it an tried to us the code an it s...  \n",
       "2                                            Easy to use  \n",
       "3                                            Easy to use  \n",
       "4                                             Very handy  \n",
       "...                                                  ...  \n",
       "15152                          Awesome gaming headphones  \n",
       "15153  These headphones are very comfortable and I li...  \n",
       "15154                                      Amazing Sound  \n",
       "15155  Got these for my gamer 14yr old son. He says t...  \n",
       "15156                 Excellent but can be improved more  \n",
       "\n",
       "[15157 rows x 2 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
